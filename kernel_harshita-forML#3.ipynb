{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# linear regression using cost fun and gradient decent"},{"metadata":{},"cell_type":"markdown","source":"# cost function is mean square error"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (12.0, 9.0)\n\n# Preprocessing Input data\nLinear = pd.read_csv('/kaggle/input/random-linear-regression/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Linear.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = Linear.iloc[:, 0]\nY = Linear.iloc[:, 1]\nplt.scatter(X, Y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**building model**\n*we have slope as 'm'and intercept as 'C'*\n# m = m-L*dm   (L = learning rate,dm = derivatives w.r.t m)\n# c = c-L*dc  (dc = derivatives wrt c)"},{"metadata":{},"cell_type":"markdown","source":"# dm = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n# dc = (-2/n) * sum(Y - Y_pred) # Derivative wrt c"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the model\nm = 0\nc = 0\n\nL = 0.0001  # The learning Rate\nepochs = 1000  # The number of iterations to perform gradient descent\n\nn = float(len(X)) # Number of elements in X\n\n# Performing Gradient Descent \nfor i in range(epochs): \n    Y_pred = m*X + c  # The current predicted value of Y\n    D_m = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n    D_c = (-2/n) * sum(Y - Y_pred)  # Derivative wrt c\n    m = m - L * D_m  # Update m\n    c = c - L * D_c  # Update c\n    \nprint (m, c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making predictions\nY_pred = m*X + c\n\nplt.scatter(X, Y)\nplt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='red') # predicted\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression with cost fun(max likelyhood) and gradient decent algo"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom math import exp\nplt.rcParams[\"figure.figsize\"] = (10, 6)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Logistic = pd.read_csv(\"/kaggle/input/titanic/train_data.csv\")\nLogistic.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# visualizing the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(Logistic['Age'], Logistic['Fare'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(Logistic['Age'], Logistic['Fare'], test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating the logistic regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":" #Helper function to normalize data\ndef normalize(X):\n    return X - X.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method to make predictions\ndef predict(X, b0, b1):\n    return np.array([1 / (1 + exp(-1*b0 + -1*b1*x)) for x in X])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D_b0 = -2 * sum((Y - y_pred) * y_pred * (1 - y_pred)) Deriv wrt b0\n# D_b1 = -2 * sum(X * (Y - y_pred) * y_pred*(1 - y_pred))Deriv wrt b1\n# b0 = b0 - L * D_b0\n# b1 = b1 - L * D_b1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method to train the model\ndef logistic_regression(X, Y):\n\n    X = normalize(X)\n\n    # Initializing variables\n    b0 = 0\n    b1 = 0\n    L = 0.001\n    epochs = 300\n\n    for epoch in range(epochs):\n        y_pred = predict(X, b0, b1)\n        D_b0 = -2 * sum((Y - y_pred) * y_pred * (1 - y_pred))  # Derivative of loss wrt b0\n        D_b1 = -2 * sum(X * (Y - y_pred) * y_pred * (1 - y_pred))  # Derivative of loss wrt b1\n        b0 = b0 - L * D_b0\n        b1 = b1 - L * D_b1\n    \n    return b0, b1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model\nb0, b1 = logistic_regression(X_train, y_train)\n\n# Making predictions\n# X_test = X_test.sort_values()  # Sorting values is optional only to see the line graph\nX_test_norm = normalize(X_test)\ny_pred = predict(X_test_norm, b0, b1)\ny_pred = [1 if p >= 0.5 else 0 for p in y_pred]\n\nplt.clf()\nplt.scatter(X_test, y_test)\nplt.scatter(X_test, y_pred, c=\"red\")\n# plt.plot(X_test, y_pred, c=\"red\", linestyle='-', marker='o') # Only if values are sorted\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The accuracy\naccuracy = 0\nfor i in range(len(y_pred)):\n    if y_pred[i] == y_test.iloc[i]:\n        accuracy += 1\nprint(f\"Accuracy = {accuracy / len(y_pred)}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}